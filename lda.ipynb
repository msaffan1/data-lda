{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to find topics within a corpus of emails with the **LDA** algorithm (Unsupervised Learning in NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úâÔ∏è Here is a collection of 1K+ ***unlabelled emails***. Let's try to ***extract topics*** from them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/lda_data'\n",
    "\n",
    "data = pd.read_csv(url, sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Cleaning**) ‚ùì You're used to it by now... Clean up! Store the cleaned text in a new column \"clean_text\" of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>from gldcunixbcccolumbiaedu gary l dare subjec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>from atterlepvelaacsoaklandedu cardinal ximene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>from minerkuhubccukansedu subject re ancient b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>from atterlepvelaacsoaklandedu cardinal ximene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>from vzhivovsuperiorcarletonca vladimir zhivov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...</td>\n",
       "      <td>from jerrybeskimocom jerry kaufman subject re ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>From: golchowy@alchemy.chem.utoronto.ca (Geral...</td>\n",
       "      <td>from golchowyalchemychemutorontoca gerald olch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>From: jayne@mmalt.guild.org (Jayne Kulikauskas...</td>\n",
       "      <td>from jaynemmaltguildorg jayne kulikauskas subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>From: sclark@epas.utoronto.ca (Susan Clark)\\nS...</td>\n",
       "      <td>from sclarkepasutorontoca susan clark subject ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>From: lmvec@westminster.ac.uk (William Hargrea...</td>\n",
       "      <td>from lmvecwestminsteracuk william hargreaves s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2     From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4     From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "...                                                 ...   \n",
       "1194  From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...   \n",
       "1195  From: golchowy@alchemy.chem.utoronto.ca (Geral...   \n",
       "1196  From: jayne@mmalt.guild.org (Jayne Kulikauskas...   \n",
       "1197  From: sclark@epas.utoronto.ca (Susan Clark)\\nS...   \n",
       "1198  From: lmvec@westminster.ac.uk (William Hargrea...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     from gldcunixbcccolumbiaedu gary l dare subjec...  \n",
       "1     from atterlepvelaacsoaklandedu cardinal ximene...  \n",
       "2     from minerkuhubccukansedu subject re ancient b...  \n",
       "3     from atterlepvelaacsoaklandedu cardinal ximene...  \n",
       "4     from vzhivovsuperiorcarletonca vladimir zhivov...  \n",
       "...                                                 ...  \n",
       "1194  from jerrybeskimocom jerry kaufman subject re ...  \n",
       "1195  from golchowyalchemychemutorontoca gerald olch...  \n",
       "1196  from jaynemmaltguildorg jayne kulikauskas subj...  \n",
       "1197  from sclarkepasutorontoca susan clark subject ...  \n",
       "1198  from lmvecwestminsteracuk william hargreaves s...  \n",
       "\n",
       "[1199 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(preprocessing)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training)** ‚ùì Train a LDA model to extract potential topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>accept</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>actually</th>\n",
       "      <th>adam</th>\n",
       "      <th>after</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118244</td>\n",
       "      <td>0.080304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045218</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>0.141084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows √ó 603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          able     about     above    accept  according  account  act  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "1     0.000000  0.000000  0.000000  0.071875   0.000000      0.0  0.0   \n",
       "2     0.000000  0.118244  0.080304  0.000000   0.000000      0.0  0.0   \n",
       "3     0.000000  0.049450  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "4     0.000000  0.000000  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "...        ...       ...       ...       ...        ...      ...  ...   \n",
       "1194  0.141084  0.000000  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "1195  0.000000  0.000000  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "1196  0.000000  0.000000  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "1197  0.000000  0.000000  0.000000  0.000000   0.232058      0.0  0.0   \n",
       "1198  0.000000  0.121217  0.000000  0.000000   0.000000      0.0  0.0   \n",
       "\n",
       "      actually  adam     after  ...  wrong     wrote      year  yes       yet  \\\n",
       "0          0.0   0.0  0.148971  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1          0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.063403   \n",
       "2          0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "3          0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4          0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "...        ...   ...       ...  ...    ...       ...       ...  ...       ...   \n",
       "1194       0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1195       0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1196       0.0   0.0  0.000000  ...    0.0  0.000000  0.051697  0.0  0.000000   \n",
       "1197       0.0   0.0  0.000000  ...    0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1198       0.0   0.0  0.000000  ...    0.0  0.116128  0.000000  0.0  0.106972   \n",
       "\n",
       "      york       you  young      your  youre  \n",
       "0      0.0  0.000000    0.0  0.000000    0.0  \n",
       "1      0.0  0.262909    0.0  0.000000    0.0  \n",
       "2      0.0  0.160259    0.0  0.045218    0.0  \n",
       "3      0.0  0.000000    0.0  0.000000    0.0  \n",
       "4      0.0  0.000000    0.0  0.000000    0.0  \n",
       "...    ...       ...    ...       ...    ...  \n",
       "1194   0.0  0.241756    0.0  0.511598    0.0  \n",
       "1195   0.0  0.193848    0.0  0.000000    0.0  \n",
       "1196   0.0  0.033403    0.0  0.000000    0.0  \n",
       "1197   0.0  0.000000    0.0  0.000000    0.0  \n",
       "1198   0.0  0.246432    0.0  0.000000    0.0  \n",
       "\n",
       "[1199 rows x 603 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, max_features=5000, min_df=50)\n",
    "\n",
    "vectorized_documents = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Instantiate the LDA \n",
    "n_components = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components, max_iter = 100)\n",
    "lda_model.fit(vectorized_documents)\n",
    "topic_word_mixture = pd.DataFrame(\n",
    "    vectorized_documents.toarray(), \n",
    "    columns = vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "topic_word_mixture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded for you a  function that prints the words associated with the potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Print the topics extracted by your LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('la', 5.5106869152831885), ('center', 1.1840208013675395), ('distribution', 1.1063524847121604), ('just', 0.6505251931762636), ('usa', 0.6118299159598204), ('flame', 0.579228123936542), ('university', 0.563994268496561), ('please', 0.49276629207711165), ('andrew', 0.45688158215177244), ('no', 0.3492755273860856)]\n",
      "Topic 1:\n",
      "[('period', 5.298462379499342), ('power', 2.825890070108786), ('play', 2.196654059610108), ('third', 1.6724529011341769), ('second', 1.3427931044335693), ('ranger', 1.3342275062745534), ('islander', 1.10051013180538), ('new', 1.0612330838617776), ('first', 1.0434957641798122), ('detroit', 1.0189386577745254)]\n",
      "Topic 2:\n",
      "[('fan', 0.78671738292884), ('coverage', 0.5383334479305526), ('th', 0.5141246271056759), ('help', 0.4758841962790922), ('university', 0.2805004415886749), ('spirit', 0.10000059604803019), ('calgary', 0.10000049117246393), ('study', 0.10000046079021713), ('blue', 0.10000045316030935), ('father', 0.10000044137426663)]\n",
      "Topic 3:\n",
      "[('that', 83.47936443410455), ('is', 82.49240060367876), ('it', 56.053950989664436), ('not', 50.31637595706983), ('god', 49.23225091254164), ('you', 47.796443244287474), ('are', 43.88275356909256), ('this', 41.58526298563762), ('we', 41.185005429312035), ('be', 40.6530524741597)]\n",
      "Topic 4:\n",
      "[('won', 1.7993213207557104), ('post', 1.4593279287362146), ('please', 1.4094096586248832), ('writes', 0.5484545500320264), ('pittsburgh', 0.5250929139807207), ('university', 0.4880376179376342), ('re', 0.4778990912367873), ('nntppostinghost', 0.42625989175024814), ('computer', 0.10043721479866631), ('spirit', 0.10000055802698178)]\n",
      "Topic 5:\n",
      "[('team', 44.135259787251385), ('game', 43.799985067639), ('for', 38.641203721406875), ('is', 37.35380332439122), ('it', 35.88603585447825), ('that', 35.53900783999269), ('he', 33.09715822520976), ('wa', 32.87378973434787), ('on', 32.177811987537815), ('hockey', 31.65248744183647)]\n",
      "Topic 6:\n",
      "[('spirit', 0.10000061693232772), ('calgary', 0.10000050838278401), ('study', 0.10000047693416816), ('blue', 0.10000046902471997), ('father', 0.10000045676077556), ('fan', 0.10000034972367067), ('wing', 0.10000034123308278), ('nntppostinghost', 0.10000032505500198), ('flyer', 0.10000032099341834), ('jesus', 0.10000026320578152)]\n",
      "Topic 7:\n",
      "[('april', 1.7762003256007994), ('above', 1.3590846644421721), ('love', 1.0857717670938325), ('group', 0.9489259515471008), ('usa', 0.720295238043789), ('another', 0.6750472194975121), ('canada', 0.5868947476964609), ('roman', 0.4637931923735178), ('one', 0.45835334384827375), ('sin', 0.4265959282555175)]\n",
      "Topic 8:\n",
      "[('spirit', 0.10000061693232772), ('calgary', 0.10000050838278401), ('study', 0.10000047693416816), ('blue', 0.10000046902471997), ('father', 0.10000045676077556), ('fan', 0.10000034972367067), ('wing', 0.10000034123308278), ('nntppostinghost', 0.10000032505500198), ('flyer', 0.10000032099341834), ('jesus', 0.10000026320578152)]\n",
      "Topic 9:\n",
      "[('distribution', 0.8394939888195058), ('message', 0.765689200212419), ('none', 0.6111670317581712), ('dept', 0.5916881164795919), ('science', 0.4979023290924173), ('only', 0.4569697139372758), ('keywords', 0.4384331359281548), ('am', 0.4147345874597823), ('home', 0.4050376895053873), ('replyto', 0.35586677691778035)]\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Predict the document-topic mixture of a new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Prediction)** ‚ùì\n",
    "\n",
    "Now that your LDA model is fitted, you can use it to predict the topics of a new text.\n",
    "\n",
    "1. Vectorize the example\n",
    "2. Use the LDA on the vectorized example to predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02276932, 0.02277008, 0.02276932, 0.02277325, 0.02276932,\n",
       "        0.7950708 , 0.02276932, 0.02276953, 0.02276932, 0.02276972]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the new text using the TF-IDF vectorizer\n",
    "example_vectorized = vectorizer.transform(example)\n",
    "\n",
    "# Use the fitted LDA model to predict the topics of the vectorized new text\n",
    "predicted_topics = lda_model.transform(example_vectorized)\n",
    "predicted_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You know how to implement an LDA quickly.\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
